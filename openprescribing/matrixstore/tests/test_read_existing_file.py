import json
import os
import platform
import sqlite3
import subprocess
import sys
from itertools import product
from random import Random

import numpy
from django.test import SimpleTestCase
from matrixstore.matrix_ops import finalise_matrix, sparse_matrix
from matrixstore.serializer import deserialize, serialize, serialize_compressed


class TestReadExistingFile(SimpleTestCase):
    """
    This tests that we can still correctly read serialized matrices (sparse,
    dense, compressed and uncompressed) from an SQLite fixture created by a
    previous version of the software. This should catch any backwards
    incompatibilities introduced by upgrading our dependencies, in particular
    PyArrow. The fixture file can be regenerated by calling the
    `create_fixture` class method on this class i.e by running:

    ./manage.py shell -c 'import matrixstore.tests.test_read_existing_file as t; t.TestReadExistingFile.create_fixture()'
    """

    fixture_db_path = "matrixstore/tests/fixtures/read_existing_file.sqlite"
    fixture_json_path = "matrixstore/tests/fixtures/read_existing_file.json"

    def test_values_can_be_read_correctly(self):
        connection = self.get_fixture_connection()
        with open(self.fixture_json_path) as f:
            expected_values = json.load(f)
        for key, expected_value in expected_values.items():
            result = connection.execute("SELECT value FROM data WHERE key=?", [key])
            value = deserialize(result.fetchone()[0])
            self.assertEqual(type(value).__name__, expected_value["type"])
            if hasattr(value, "todense"):
                value = value.todense()
            self.assertEqual(value.tolist(), expected_value["value"])

    def get_fixture_connection(self):
        if not os.path.exists(self.fixture_db_path):
            raise RuntimeError(
                "No SQLite file at: {fixture_db_path}\n\n"
                "To create the fixture, run:\n"
                "  ./manage.py shell -c"
                '  "from {module} import {cls}; {cls}.create_fixture()"'.format(
                    fixture_db_path=self.fixture_db_path,
                    module=__name__,
                    cls=self.__class__.__name__,
                )
            )
        return sqlite3.connect(self.fixture_db_path)

    @classmethod
    def generate_test_values(cls):
        random = Random()
        random.seed(1204)
        for sparse, integer, compressed in product([True, False], repeat=3):
            matrix = cls.make_matrix(random, sparse, integer)
            key = "{structure}.{type}.{format}".format(
                structure="sparse" if sparse else "dense",
                type="integer" if integer else "float",
                format="compressed" if compressed else "uncompressed",
            )
            yield key, matrix

    @classmethod
    def make_matrix(self, random, sparse, integer):
        shape = (16, 4)
        if sparse:
            matrix = sparse_matrix(shape, integer=integer)
        else:
            dtype = numpy.int64 if integer else numpy.float64
            matrix = numpy.zeros(shape, dtype=dtype)
        coords = list(map(random.randrange, shape))
        value = random.randrange(128) if integer else random.random()
        matrix[coords] = value
        if sparse:
            matrix = finalise_matrix(matrix)
        # Check we've got the type of matrix we're expecting
        assert hasattr(matrix, "todense") == sparse
        return matrix

    @classmethod
    def create_fixture(cls):
        temp_db_path = cls.fixture_db_path + ".tmp"
        if os.path.exists(temp_db_path):
            os.unlink(temp_db_path)
        connection = sqlite3.connect(temp_db_path)
        connection.executescript(
            """
            CREATE TABLE data (key TEXT, value BLOB);
            CREATE TABLE environment_metadata (key TEXT, value TEXT);
            """
        )
        json_data = {}
        for key, value in cls.generate_test_values():
            json_value = value
            if hasattr(value, "todense"):
                json_value = json_value.todense()
            json_data[key] = {
                "type": type(value).__name__,
                "value": json_value.tolist(),
            }
            if ".uncompressed" in key:
                data = serialize(value)
            elif ".compressed" in key:
                data = serialize_compressed(value)
            else:
                raise RuntimeError("Invalid key")
            connection.execute("INSERT INTO data VALUES (?, ?)", [key, data])
        for key, value in cls.get_environment_metadata():
            connection.execute(
                "INSERT INTO environment_metadata VALUES (?, ?)", [key, value]
            )
        connection.commit()
        connection.close()
        os.rename(temp_db_path, cls.fixture_db_path)
        with open(cls.fixture_json_path, "w") as f:
            json.dump(json_data, f, indent=2)

    @classmethod
    def get_environment_metadata(cls):
        """
        Yields various bits of metadata about the current environment (Python
        version, installed package versions etc) which might be useful in
        debugging failures
        """
        yield "python_version", platform.python_version()
        yield "platform", platform.platform()
        installed_packages = subprocess.check_output(
            [sys.executable, "-m", "pip", "freeze", "-qqq"]
        )
        yield "installed_packages", installed_packages
